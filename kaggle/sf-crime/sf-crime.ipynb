{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: San Francisco Crime Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the category of crimes that occurred in the city by the bay\n",
    "\n",
    "From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz.\n",
    "\n",
    "Today, the city is known more for its tech scene than its criminal past. But, with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity of crime in the city by the bay.\n",
    "\n",
    "From Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to add\n",
    "# probability parameter\n",
    "# call .decision_function(x) to get probabilities\n",
    "\n",
    "# normalize your features\n",
    "# try day of year, day or month, day of week, hour of day...\n",
    "# polarize features, as done in the M&V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, preprocessing\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from os.path import expanduser, normpath\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set paths for data to be imported\n",
    "\n",
    "home = expanduser('~')\n",
    "# path = str(home) + '\\\\Documents\\\\data-science\\\\kaggle\\\\sf-crime\\\\' # Windows\n",
    "path = str(home) + '/Documents/Personal/data-science/kaggle/sf-crime/' # Mac\n",
    "trainfile = 'train.csv'\n",
    "testfile = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv(path+trainfile)\n",
    "test_data_raw = pd.read_csv(path+testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_data.groupby('Category').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARCENY/THEFT                  174900\n",
       "OTHER OFFENSES                 126182\n",
       "NON-CRIMINAL                    92304\n",
       "ASSAULT                         76876\n",
       "DRUG/NARCOTIC                   53971\n",
       "VEHICLE THEFT                   53781\n",
       "VANDALISM                       44725\n",
       "WARRANTS                        42214\n",
       "BURGLARY                        36755\n",
       "SUSPICIOUS OCC                  31414\n",
       "MISSING PERSON                  25989\n",
       "ROBBERY                         23000\n",
       "FRAUD                           16679\n",
       "FORGERY/COUNTERFEITING          10609\n",
       "SECONDARY CODES                  9985\n",
       "WEAPON LAWS                      8555\n",
       "PROSTITUTION                     7484\n",
       "TRESPASS                         7326\n",
       "STOLEN PROPERTY                  4540\n",
       "SEX OFFENSES FORCIBLE            4388\n",
       "DISORDERLY CONDUCT               4320\n",
       "DRUNKENNESS                      4280\n",
       "RECOVERED VEHICLE                3138\n",
       "KIDNAPPING                       2341\n",
       "DRIVING UNDER THE INFLUENCE      2268\n",
       "RUNAWAY                          1946\n",
       "LIQUOR LAWS                      1903\n",
       "ARSON                            1513\n",
       "LOITERING                        1225\n",
       "EMBEZZLEMENT                     1166\n",
       "SUICIDE                           508\n",
       "FAMILY OFFENSES                   491\n",
       "BAD CHECKS                        406\n",
       "BRIBERY                           289\n",
       "EXTORTION                         256\n",
       "SEX OFFENSES NON FORCIBLE         148\n",
       "GAMBLING                          146\n",
       "PORNOGRAPHY/OBSCENE MAT            22\n",
       "TREA                                6\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data_raw.copy()\n",
    "test_data = test_data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary features\n",
    "train_data.drop(['Descript', \n",
    "                 'Resolution', \n",
    "                 'PdDistrict', \n",
    "                 'DayOfWeek', \n",
    "                 'Address'], inplace=True, axis=1)\n",
    "\n",
    "test_data.drop(['PdDistrict', \n",
    "                'DayOfWeek', \n",
    "                'Address'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['Dates'] = pd.to_datetime(train_data['Dates'])\n",
    "train_data['year'] = train_data['Dates'].dt.year\n",
    "train_data['month'] = train_data['Dates'].dt.month \n",
    "train_data['day'] = train_data['Dates'].dt.day\n",
    "train_data['hour'] = train_data['Dates'].dt.hour\n",
    "train_data['minute'] = train_data['Dates'].dt.minute\n",
    "\n",
    "train_data['dayofyear'] = train_data['Dates'].dt.dayofyear\n",
    "train_data['dayofweek'] = train_data['Dates'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['Dates'] = pd.to_datetime(test_data['Dates'])\n",
    "test_data['year'] = test_data['Dates'].dt.year\n",
    "test_data['month'] = test_data['Dates'].dt.month \n",
    "test_data['day'] = test_data['Dates'].dt.day\n",
    "test_data['hour'] = test_data['Dates'].dt.hour\n",
    "test_data['minute'] = test_data['Dates'].dt.minute\n",
    "\n",
    "test_data['dayofyear'] = test_data['Dates'].dt.dayofyear\n",
    "test_data['dayofweek'] = test_data['Dates'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up 0 to 1 scaler for preprocessing features in training and test sets\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_noscale = pd.DataFrame(train_data[['Category','Dates']])\n",
    "train_data.drop(['Category', 'Dates'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_minmax = pd.DataFrame(min_max_scaler.fit_transform(train_data),\n",
    "                                 index = train_data.index, \n",
    "                                 columns = train_data.columns) \n",
    "train_data_minmax[['Category','Dates']] = train_data_noscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_noscale= pd.DataFrame(test_data[['Id','Dates']])\n",
    "test_data.drop(['Id', 'Dates'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_minmax = pd.DataFrame(min_max_scaler.transform(test_data),\n",
    "                                index = test_data.index, \n",
    "                                columns = test_data.columns) \n",
    "test_data_minmax[['Id','Dates']] = test_data_noscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate training and cross-validation features\n",
    "X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(train_data_minmax.ix[:,['dayofyear','dayofweek','hour','X','Y']], \n",
    "                                                                 train_data_minmax.ix[:,'Category'], \n",
    "                                                                 test_size=0.80, \n",
    "                                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data.ix[:,['dayofyear','dayofweek','hour','X','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # polarize data\n",
    "#     if tod:\n",
    "#         times = index.hour\n",
    "#         tody = np.cos(2*np.pi*times/24)\n",
    "#         todx = np.sin(2*np.pi*times/24)     \n",
    "        \n",
    "#         X_train[:,2] = tody[shuffling][:n_points]\n",
    "#         X_train[:,3] = todx[shuffling][:n_points]\n",
    "        \n",
    "#         X_test[:,2] = tody[shuffling][n_points:]\n",
    "#         X_test[:,3] = todx[shuffling][n_points:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split again, generate training and cross-validation features for grid search\n",
    "X_grid_train, X_grid_cv, y_grid_train, y_grid_cv = cross_validation.train_test_split(X_train, \n",
    "                                                                 y_train, \n",
    "                                                                 test_size=0.50, \n",
    "                                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'estimator__C': [100, 1000, 10000], 'estimator__gamma': [0.01, 0.001, 0.0001], 'estimator__kernel': ['rbf']}\n",
    "]\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = GridSearchCV(OneVsRestClassifier(SVC()), param_grid, error_score=0)\n",
    "clf.fit(X_grid_train, y_grid_train)\n",
    "\n",
    "print(clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for score in scores:\n",
    "#     print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "#     print()\n",
    "\n",
    "#     clf = GridSearchCV(OneVsRestClassifier(SVC()), param_grid,\n",
    "#                        scoring='%s_weighted' % score)\n",
    "#     clf.fit(X_grid_train, y_grid_train)\n",
    "\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print()\n",
    "#     print(clf.best_params_)\n",
    "#     print()\n",
    "#     print(\"Grid scores on development set:\")\n",
    "#     print()\n",
    "#     for params, mean_score, scores in clf.grid_scores_:\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "#               % (mean_score, scores.std() * 2, params))\n",
    "#     print()\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print()\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print()\n",
    "#     y_true, y_pred = y_grid_cv, clf.predict(X_grid_cv)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run for 5% of sample set, ~1.5 hour run time\n",
    "# # Tuning hyper-parameters for precision\n",
    "\n",
    "# {'estimator__C': 1000, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "\n",
    "# Grid scores on development set:\n",
    "\n",
    "# 0.140 (+/-0.162) for {'estimator__C': 1, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.093 (+/-0.168) for {'estimator__C': 1, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.137 (+/-0.194) for {'estimator__C': 10, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.091 (+/-0.159) for {'estimator__C': 10, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.134 (+/-0.116) for {'estimator__C': 100, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.091 (+/-0.160) for {'estimator__C': 100, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.154 (+/-0.123) for {'estimator__C': 1000, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.131 (+/-0.186) for {'estimator__C': 1000, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "\n",
    "# Detailed classification report:\n",
    "\n",
    "# The model is trained on the full development set.\n",
    "# The scores are computed on the full evaluation set.\n",
    "\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#       ARSON       0.00      0.00      0.00        87\n",
    "#     ASSAULT       0.00      0.00      0.00      3827\n",
    "#  BAD CHECKS       0.00      0.00      0.00        19\n",
    "#     BRIBERY       0.00      0.00      0.00        13\n",
    "#    BURGLARY       0.00      0.00      0.00      1877\n",
    "# DISORDERLY CONDUCT       0.00      0.00      0.00       219\n",
    "# DRIVING UNDER THE INFLUENCE       0.00      0.00      0.00       121\n",
    "# DRUG/NARCOTIC       0.00      0.00      0.00      2789\n",
    "# DRUNKENNESS       0.00      0.00      0.00       222\n",
    "# EMBEZZLEMENT       0.00      0.00      0.00        59\n",
    "#   EXTORTION       0.00      0.18      0.00        11\n",
    "# FAMILY OFFENSES       0.00      0.09      0.00        23\n",
    "# FORGERY/COUNTERFEITING       0.00      0.00      0.00       545\n",
    "#       FRAUD       0.00      0.00      0.00       846\n",
    "#    GAMBLING       0.00      0.00      0.00        11\n",
    "#  KIDNAPPING       0.00      0.00      0.00       118\n",
    "# LARCENY/THEFT       0.33      0.00      0.00      8772\n",
    "# LIQUOR LAWS       0.00      0.00      0.00        87\n",
    "#   LOITERING       0.00      0.00      0.00        62\n",
    "# MISSING PERSON       0.00      0.00      0.00      1372\n",
    "# NON-CRIMINAL       0.00      0.00      0.00      4541\n",
    "# OTHER OFFENSES       0.00      0.00      0.00      6345\n",
    "# PORNOGRAPHY/OBSCENE MAT       0.00      1.00      0.00         2\n",
    "# PROSTITUTION       0.00      0.00      0.00       361\n",
    "# RECOVERED VEHICLE       0.00      0.00      0.00       138\n",
    "#     ROBBERY       0.00      0.00      0.00      1151\n",
    "#     RUNAWAY       0.00      0.00      0.00       102\n",
    "# SECONDARY CODES       0.00      0.00      0.00       485\n",
    "# SEX OFFENSES FORCIBLE       0.00      0.00      0.00       199\n",
    "# SEX OFFENSES NON FORCIBLE       0.00      0.00      0.00        10\n",
    "# STOLEN PROPERTY       0.00      0.00      0.00       225\n",
    "#     SUICIDE       0.00      0.00      0.00        26\n",
    "# SUSPICIOUS OCC       0.00      0.00      0.00      1512\n",
    "#        TREA       0.00      0.00      0.00         0\n",
    "#    TRESPASS       0.00      0.00      0.00       344\n",
    "#   VANDALISM       0.00      0.00      0.00      2204\n",
    "# VEHICLE THEFT       0.00      0.00      0.00      2625\n",
    "#    WARRANTS       0.00      0.00      0.00      2148\n",
    "# WEAPON LAWS       0.00      0.00      0.00       404\n",
    "\n",
    "# avg / total       0.07      0.00      0.00     43902\n",
    "\n",
    "# # Tuning hyper-parameters for recall\n",
    "\n",
    "# {'estimator__C': 10, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "\n",
    "# Grid scores on development set:\n",
    "\n",
    "# 0.006 (+/-0.005) for {'estimator__C': 1, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.030 (+/-0.036) for {'estimator__C': 1, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.002 (+/-0.001) for {'estimator__C': 10, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.033 (+/-0.006) for {'estimator__C': 10, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.013 (+/-0.028) for {'estimator__C': 100, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.007 (+/-0.006) for {'estimator__C': 100, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "# 0.002 (+/-0.005) for {'estimator__C': 1000, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.001}\n",
    "# 0.000 (+/-0.000) for {'estimator__C': 1000, 'estimator__kernel': 'rbf', 'estimator__gamma': 0.0001}\n",
    "\n",
    "# Detailed classification report:\n",
    "\n",
    "# The model is trained on the full development set.\n",
    "# The scores are computed on the full evaluation set.\n",
    "\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#       ARSON       0.00      0.00      0.00        87\n",
    "#     ASSAULT       0.00      0.00      0.00      3827\n",
    "#  BAD CHECKS       0.00      0.00      0.00        19\n",
    "#     BRIBERY       0.00      0.00      0.00        13\n",
    "#    BURGLARY       0.00      0.00      0.00      1877\n",
    "# DISORDERLY CONDUCT       0.02      0.02      0.02       219\n",
    "# DRIVING UNDER THE INFLUENCE       0.00      0.00      0.00       121\n",
    "# DRUG/NARCOTIC       0.00      0.00      0.00      2789\n",
    "# DRUNKENNESS       0.00      0.00      0.00       222\n",
    "# EMBEZZLEMENT       0.00      0.00      0.00        59\n",
    "#   EXTORTION       0.00      0.00      0.00        11\n",
    "# FAMILY OFFENSES       0.00      0.00      0.00        23\n",
    "# FORGERY/COUNTERFEITING       0.00      0.00      0.00       545\n",
    "#       FRAUD       0.00      0.00      0.00       846\n",
    "#    GAMBLING       0.00      0.00      0.00        11\n",
    "#  KIDNAPPING       0.00      0.00      0.00       118\n",
    "# LARCENY/THEFT       0.33      0.00      0.00      8772\n",
    "# LIQUOR LAWS       0.00      0.00      0.00        87\n",
    "#   LOITERING       0.00      0.00      0.00        62\n",
    "# MISSING PERSON       0.00      0.00      0.00      1372\n",
    "# NON-CRIMINAL       0.00      0.00      0.00      4541\n",
    "# OTHER OFFENSES       0.00      0.00      0.00      6345\n",
    "# PORNOGRAPHY/OBSCENE MAT       0.00      0.00      0.00         2\n",
    "# PROSTITUTION       0.00      0.00      0.00       361\n",
    "# RECOVERED VEHICLE       0.00      0.00      0.00       138\n",
    "#     ROBBERY       0.00      0.00      0.00      1151\n",
    "#     RUNAWAY       0.00      0.00      0.00       102\n",
    "# SECONDARY CODES       0.00      0.00      0.00       485\n",
    "# SEX OFFENSES FORCIBLE       0.00      0.00      0.00       199\n",
    "# SEX OFFENSES NON FORCIBLE       0.00      0.00      0.00        10\n",
    "# STOLEN PROPERTY       0.00      0.00      0.00       225\n",
    "#     SUICIDE       0.00      0.00      0.00        26\n",
    "# SUSPICIOUS OCC       0.03      0.29      0.06      1512\n",
    "#    TRESPASS       0.00      0.00      0.00       344\n",
    "#   VANDALISM       0.05      0.33      0.09      2204\n",
    "# VEHICLE THEFT       0.00      0.00      0.00      2625\n",
    "#    WARRANTS       0.00      0.00      0.00      2148\n",
    "# WEAPON LAWS       0.01      0.39      0.02       404\n",
    "\n",
    "# avg / total       0.07      0.03      0.01     43902"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SUPPORT VECTOR MACHINE\n",
    "t0 = time.time()\n",
    "\n",
    "crime_svm = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "crime_svm.fit(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "score_train = crime_svm.score(X_train, y_train)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print ('Score:', score_train, ', Time:', total) # Score:  0.0880649625019 , Time:  0.27322959899902344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "score_cv = crime_svm.score(X_cv, y_cv)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print ('Score:', score_cv, ', Time:', total) # Score:  0.0874252605205 , Time:  1.2154865264892578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "output = crime_svm.predict(X_test)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print ('Time:', total) # Time: 0.3079204559326172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_uniques = train_data_raw.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = 'Id,' + ','.join(sorted(cat_uniques)) + '\\n'\n",
    "f = open('y_test.csv', 'w')\n",
    "f.write(headers)\n",
    "for i in xrange(len(y_test)):\n",
    "    arr = [0] * 39\n",
    "    arr[int(y_test)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
